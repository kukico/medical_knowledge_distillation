{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f944b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change directory to the specified path\n",
    "os.chdir('/rds/general/user/sw3720/home/codes/Python/Knowledge_Distillation')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b77fc",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ea7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    accuracy_score, recall_score, confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b1459",
   "metadata": {},
   "source": [
    "## Parameters and Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283cd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_DEFAULT_PARAMS = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'booster': 'gbtree',\n",
    "    'reg_alpha': 0.05,\n",
    "    'reg_lambda': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "CV_FOLDS = 5\n",
    "BOOTSTRAP_ITERATIONS = 1000\n",
    "EARLY_STOPPING_NORMAL = 1000\n",
    "EARLY_STOPPING_KD = 500\n",
    "DEFAULT_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e394a",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1bdf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specificity(y_true, y_pred):\n",
    "    \"\"\"Compute specificity: TN / (TN + FP).\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "\n",
    "\n",
    "def bootstrap_confidence_interval(y_true, y_scores, metric='roc', n_iters=BOOTSTRAP_ITERATIONS, alpha=0.05, random_state=42):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence intervals for ROC AUC or AUPRC.\n",
    "    metric: 'roc' or 'pr'. Returns (lower_ci, upper_ci).\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    scores = []\n",
    "    n = len(y_true)\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        idx = rng.randint(0, n, n)\n",
    "        if len(np.unique(y_true[idx])) < 2:\n",
    "            continue\n",
    "        if metric == 'roc':\n",
    "            fpr, tpr, _ = roc_curve(y_true[idx], y_scores[idx])\n",
    "            scores.append(auc(fpr, tpr))\n",
    "        else:\n",
    "            prec, rec, _ = precision_recall_curve(y_true[idx], y_scores[idx])\n",
    "            scores.append(auc(rec, prec))\n",
    "\n",
    "    lower = np.percentile(scores, 100 * (alpha / 2))\n",
    "    upper = np.percentile(scores, 100 * (1 - alpha / 2))\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "def compute_classification_metrics(y_true, y_scores, threshold=DEFAULT_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Compute key classification metrics and return as a dict.\n",
    "    \"\"\"\n",
    "    y_pred = (y_scores > threshold).astype(int)\n",
    "    metrics = {\n",
    "        'precision': average_precision_score(y_true, y_scores),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'specificity': get_specificity(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    metrics['roc_auc'] = roc_auc\n",
    "\n",
    "    # AUPRC\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_scores)\n",
    "    auprc = auc(rec, prec)\n",
    "    metrics['auprc'] = auprc\n",
    "\n",
    "    return metrics, (fpr, tpr)\n",
    "\n",
    "# ------------------------------------\n",
    "# Custom Loss for Knowledge Distillation\n",
    "# ------------------------------------\n",
    "def distillation_gradient_hessian(preds, dtrain, alpha=0.4, temperature=1.2):\n",
    "    \"\"\"\n",
    "    Custom objective: combined gradient/hessian for knowledge distillation.\n",
    "    dtrain.weight contains teacher probabilities.\n",
    "    \"\"\"\n",
    "    labels = dtrain.get_label()\n",
    "    teacher_probs = dtrain.get_weight()\n",
    "\n",
    "    # Student probabilities\n",
    "    preds_prob = 1 / (1 + np.exp(-preds))\n",
    "    # Teacher probabilities (scaled)\n",
    "    teacher_logits = np.log(teacher_probs / (1 - teacher_probs))\n",
    "    scaled_teacher_logits = teacher_logits / temperature\n",
    "    teacher_scaled_prob = 1 / (1 + np.exp(-scaled_teacher_logits))\n",
    "\n",
    "    # Gradients\n",
    "    grad_ce = preds_prob - labels\n",
    "    grad_kl = -teacher_scaled_prob * (1 - preds_prob)\n",
    "    grad = alpha * grad_ce + (1 - alpha) * temperature**2 * grad_kl\n",
    "\n",
    "    # Hessians\n",
    "    hess_ce = preds_prob * (1 - preds_prob)\n",
    "    hess_kl = teacher_scaled_prob * preds_prob * (1 - preds_prob) * (1 - 2 * preds_prob)\n",
    "    hess = alpha * hess_ce + (1 - alpha) * temperature**2 * hess_kl\n",
    "\n",
    "    return grad, hess\n",
    "\n",
    "# ------------------------------------\n",
    "# Model Training and Evaluation\n",
    "# ------------------------------------\n",
    "\n",
    "def train_xgb_model(\n",
    "    X_train, y_train,\n",
    "    params=XGB_DEFAULT_PARAMS,\n",
    "    early_stopping_rounds=EARLY_STOPPING_NORMAL,\n",
    "    kd_enabled=False,\n",
    "    soft_labels=None,\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model (with optional KD) on provided data.\n",
    "    soft_labels required if kd_enabled is True.\n",
    "    \"\"\"\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, weight=soft_labels if soft_labels is not None else None)\n",
    "    evals = [(dtrain, 'train')]\n",
    "\n",
    "    if kd_enabled:\n",
    "        obj = distillation_gradient_hessian\n",
    "        esr = EARLY_STOPPING_KD\n",
    "    else:\n",
    "        obj = None\n",
    "        esr = early_stopping_rounds\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=10000,\n",
    "        obj=obj,\n",
    "        evals=evals,\n",
    "        verbose_eval=verbose,\n",
    "        early_stopping_rounds=esr\n",
    "    )\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "def cross_validate_xgb(\n",
    "    features, labels,\n",
    "    params=XGB_DEFAULT_PARAMS,\n",
    "    n_splits=CV_FOLDS,\n",
    "    kd_enabled=False,\n",
    "    soft_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform K-fold CV for training and evaluation.\n",
    "    Returns results dict with metrics, ROC data, mean ROC, CI, and last model.\n",
    "    \"\"\"\n",
    "    X = np.asarray(features)\n",
    "    y = np.asarray(labels)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    roc_data = []\n",
    "    all_metrics = []\n",
    "    roc_aucs = []\n",
    "    pr_aucs = []\n",
    "    roc_cis = []\n",
    "    pr_cis = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx], y[test_idx]\n",
    "        soft_tr = soft_labels[train_idx] if soft_labels is not None else None\n",
    "\n",
    "        model = train_xgb_model(\n",
    "            X_tr, y_tr,\n",
    "            params=params,\n",
    "            kd_enabled=kd_enabled,\n",
    "            soft_labels=soft_tr\n",
    "        )\n",
    "\n",
    "        dtest = xgb.DMatrix(X_te, label=y_te)\n",
    "        y_prob = model.predict(dtest)\n",
    "\n",
    "        metrics, (fpr, tpr) = compute_classification_metrics(y_te, y_prob)\n",
    "        all_metrics.append(metrics)\n",
    "        roc_data.append((fpr, tpr, metrics['roc_auc']))\n",
    "        roc_aucs.append(metrics['roc_auc'])\n",
    "        pr_aucs.append(metrics['auprc'])\n",
    "        roc_cis.append(bootstrap_confidence_interval(y_te, y_prob, 'roc'))\n",
    "        pr_cis.append(bootstrap_confidence_interval(y_te, y_prob, 'pr'))\n",
    "\n",
    "        # Interpolate for mean ROC\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "\n",
    "    # Aggregate\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_metrics = {k: np.mean([m[k] for m in all_metrics]) for k in all_metrics[0]}\n",
    "    ci = {\n",
    "        'roc_auc': (\n",
    "            np.mean([low for low, high in roc_cis]),\n",
    "            np.mean([high for low, high in roc_cis])\n",
    "        ),\n",
    "        'pr_auc': (\n",
    "            np.mean([low for low, high in pr_cis]),\n",
    "            np.mean([high for low, high in pr_cis])\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': mean_metrics,\n",
    "        'roc_data': roc_data,\n",
    "        'mean_roc': (mean_fpr, mean_tpr),\n",
    "        'ci': ci,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# ------------------------------------\n",
    "# Inference\n",
    "# ------------------------------------\n",
    "def inference_xgb(test_df, test_labels, model, feature_col='patientunitstay'):\n",
    "    \"\"\"\n",
    "    Perform inference and compute metrics for new dataset.\n",
    "    Expects a DataFrame test_df including 'patientunitstay'.\n",
    "    Returns dict with metrics, ROC data, mean ROC, CI, and model.\n",
    "    \"\"\"\n",
    "    X_test = test_df.drop(columns=[feature_col])\n",
    "    y_test = np.asarray(test_labels)\n",
    "\n",
    "    if isinstance(model, xgb.Booster):\n",
    "        y_prob = model.predict(xgb.DMatrix(X_test))\n",
    "    else:\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics, (fpr, tpr) = compute_classification_metrics(y_test, y_prob)\n",
    "    roc_ci = bootstrap_confidence_interval(y_test, y_prob, 'roc')\n",
    "    pr_ci = bootstrap_confidence_interval(y_test, y_prob, 'pr')\n",
    "\n",
    "    # mean ROC as a single fold\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    mean_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0], mean_tpr[-1] = 0.0, 1.0\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'roc_data': [(fpr, tpr, metrics['roc_auc'])],\n",
    "        'mean_roc': (mean_fpr, mean_tpr),\n",
    "        'ci': {'roc_auc': roc_ci, 'pr_auc': pr_ci},\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# ------------------------------------\n",
    "# Plotting\n",
    "# ------------------------------------\n",
    "def plot_roc_curve(roc_data, mean_roc, ci):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for each fold and the mean ROC with confidence intervals.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for idx, (fpr, tpr, auc_val) in enumerate(roc_data, start=1):\n",
    "        plt.plot(fpr, tpr, alpha=0.3, lw=1,\n",
    "                 label=f'Fold {idx} ROC (AUC={auc_val:.2f})')\n",
    "\n",
    "    mean_fpr, mean_tpr = mean_roc\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    lower, upper = ci['roc_auc']\n",
    "    plt.plot(mean_fpr, mean_tpr, lw=2,\n",
    "             label=f'Mean ROC (AUC={mean_auc:.2f} Â± [{lower:.2f}, {upper:.2f}])')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2,\n",
    "             label='Random Guess')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898fa6b7",
   "metadata": {},
   "source": [
    "## Model Trained on MIMIC-III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MIMIC-III data and labels\n",
    "mimic_df = joblib.load('Variables/mimic_iii_data.pkl')\n",
    "mimic_labels = joblib.load('Variables/mimic_iii_label.pkl')\n",
    "\n",
    "# Full feature model\n",
    "full_results = cross_validate_xgb(mimic_df, mimic_labels)\n",
    "plot_roc_curve(full_results['roc_data'], full_results['mean_roc'], full_results['ci'])\n",
    "print(\"Full Model Metrics:\")\n",
    "for metric, value in full_results['metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a2188",
   "metadata": {},
   "source": [
    "## Model Trained on MIMIC-III with Limited Features Available in eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b398213",
   "metadata": {},
   "outputs": [],
   "source": [
    "eicu_df = joblib.load('Variables/eicu_data.pkl')\n",
    "eicu_labels = joblib.load('Variables/eicu_label.pkl')\n",
    "# Limited feature CV\n",
    "common_features = eicu_df.drop(columns=['patientunitstay']).columns.tolist()\n",
    "mimic_limited_df = mimic_df[common_features]\n",
    "limited_results = cross_validate_xgb(mimic_limited_df, mimic_labels)\n",
    "small_model = limited_results['model']\n",
    "\n",
    "# Inference on eICU\n",
    "inf_results = inference_xgb(eicu_df, eicu_labels, small_model)\n",
    "print(\"\\nSmall Model Inference Metrics:\")\n",
    "for metric, value in inf_results['metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab289d",
   "metadata": {},
   "source": [
    "## Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e983e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster_df = xgb.DMatrix(mimic_df, label=mimic_labels)\n",
    "teacher_scores = full_results['model'].predict(booster_df)\n",
    "distilled_results = cross_validate_xgb(\n",
    "    mimic_limited_df, mimic_labels,\n",
    "    kd_enabled=True,\n",
    "    soft_labels=teacher_scores\n",
    ")\n",
    "distilled_model = distilled_results['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c484",
   "metadata": {},
   "source": [
    "## Model Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_model.save_model('Models/mimic_distilled.model')\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.load_model('Models/mimic_distilled.model')\n",
    "calibrated_clf = CalibratedClassifierCV(\n",
    "    estimator=clf, method='isotonic', cv='prefit'\n",
    ")\n",
    "calibrated_clf.fit(\n",
    "    eicu_df.drop(columns=['patientunitstay']),\n",
    "    eicu_labels\n",
    ")\n",
    "cal_inf_results = inference_xgb(eicu_df, eicu_labels, calibrated_clf)\n",
    "print(\"\\nCalibrated Model Inference Metrics:\")\n",
    "for metric, value in cal_inf_results['metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mimic-iii]",
   "language": "python",
   "name": "conda-env-mimic-iii-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
